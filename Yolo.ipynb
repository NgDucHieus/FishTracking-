{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568bab1-a2bd-48b6-a3ea-e65a95a045eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: MaMe-FeMos-FeMe-d4-5ng.MOV\n",
      "\n",
      "0: 384x640 9 fishs, 63.2ms\n",
      "Speed: 5.3ms preprocess, 63.2ms inference, 174.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 11.0ms\n",
      "Speed: 3.5ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.0ms\n",
      "Speed: 3.5ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 11.0ms\n",
      "Speed: 3.5ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.6ms\n",
      "Speed: 1.5ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 11.2ms\n",
      "Speed: 1.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 2.9ms\n",
      "Speed: 1.1ms preprocess, 2.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 fishs, 11.0ms\n",
      "Speed: 3.5ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 12.1ms\n",
      "Speed: 1.0ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 12.1ms\n",
      "Speed: 1.0ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 11.2ms\n",
      "Speed: 1.0ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.0ms\n",
      "Speed: 1.5ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 12.1ms\n",
      "Speed: 1.5ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 fishs, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ObjectTracker:\n",
    "    def __init__(self, model_path, video_folder, pixel_to_meter):\n",
    "        # Load YOLOv8 model\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "        # Initialize DeepSORT tracker\n",
    "        self.tracker = DeepSort(max_age=3, max_cosine_distance=0.01)\n",
    "\n",
    "        # Store previous positions and tracking data\n",
    "        self.previous_positions = {}\n",
    "        self.tracking_data = []\n",
    "        self.pixel_to_meter = pixel_to_meter  # Conversion factor from pixels to meters\n",
    "\n",
    "        # Get all video files in the folder\n",
    "        self.video_files = [f for f in os.listdir(video_folder) if f.endswith('.MOV')]\n",
    "        self.video_folder = video_folder\n",
    "\n",
    "        if not self.video_files:\n",
    "            raise ValueError(\"No .MOV files found in the specified video folder.\")\n",
    "\n",
    "    def calculate_velocity(self, track_id, current_position, fps):\n",
    "        if track_id in self.previous_positions:\n",
    "            previous_position = self.previous_positions[track_id]\n",
    "            displacement = np.linalg.norm(current_position - previous_position)\n",
    "            velocity = displacement * fps * self.pixel_to_meter\n",
    "        else:\n",
    "            velocity = 0\n",
    "        self.previous_positions[track_id] = current_position\n",
    "        return velocity\n",
    "\n",
    "    def draw_bounding_box(self, frame, bbox, track_id, velocity):\n",
    "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'ID: {track_id}', (int(bbox[0]), int(bbox[1])-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'Vel: {velocity:.2f} m/s', (int(bbox[0]), int(bbox[1])-40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    def process_video(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise Exception(f\"Could not open video file: {video_path}\")\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        self.previous_positions.clear()\n",
    "        self.tracking_data.clear()\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            results = self.model(frame)\n",
    "            detections = results[0].boxes.data\n",
    "\n",
    "            dets = []\n",
    "            for box in detections:\n",
    "                x1, y1, x2, y2, conf, cls = box.cpu().numpy()\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                dets.append([[x1, y1, width, height], conf])\n",
    "\n",
    "            tracks = self.tracker.update_tracks(dets, frame=frame)\n",
    "\n",
    "            for track in tracks:\n",
    "                if track.is_confirmed():\n",
    "                    track_id = track.track_id\n",
    "                    bbox = track.to_tlbr()\n",
    "                    x_center = (bbox[0] + bbox[2]) / 2\n",
    "                    y_center = (bbox[1] + bbox[3]) / 2\n",
    "                    current_position = np.array([x_center, y_center])\n",
    "\n",
    "                    velocity = self.calculate_velocity(track_id, current_position, fps)\n",
    "                    self.draw_bounding_box(frame, bbox, track_id, velocity)\n",
    "\n",
    "                    self.tracking_data.append([cap.get(cv2.CAP_PROP_POS_FRAMES), track_id, x_center, y_center, velocity])\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    def export_tracking_data(self, csv_path):\n",
    "        with open(csv_path, 'w', newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(['Frame', 'Object ID', 'X Center', 'Y Center', 'Velocity (m/s)'])\n",
    "            csvwriter.writerows(self.tracking_data)\n",
    "\n",
    "    def run(self):\n",
    "        for video_file in self.video_files:\n",
    "            video_path = os.path.join(self.video_folder, video_file)\n",
    "\n",
    "            output_folder = os.path.join(self.video_folder, video_file.replace('.MOV', '_output'))\n",
    "            if not os.path.exists(output_folder):\n",
    "                os.makedirs(output_folder)\n",
    "\n",
    "            print(f\"Processing video: {video_file}\")\n",
    "            self.process_video(video_path)\n",
    "            self.export_tracking_data(os.path.join(output_folder, f'{video_file.replace(\".MOV\", \"_tracking_data.csv\")}'))\n",
    "\n",
    "# Usage\n",
    "pixel_to_meter = 0.01  # Example conversion factor\n",
    "video_folder = r'C:\\Users\\MAY02\\Desktop\\FishTracking-\\Test'  # Ensure this path is correct\n",
    "\n",
    "tracker = ObjectTracker('bestYOLOV8x.pt', video_folder, pixel_to_meter)\n",
    "\n",
    "try:\n",
    "    tracker.run()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab0ee4-a771-4bdb-aff6-44a6b34e3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "706.0699559\t364.4589487\n",
    "706.6905643\t361.974339\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97cf4c10-7a68-4ac7-8792-e27e163c97df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4846097000000213"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "364.4589487-361.974339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7fbd5a-ef91-484b-9d76-715e580593fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fcffc5-b052-4d5f-a7cd-e28cf8b7ab52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.47894227164543"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.6206084000000374**2 + 2.4**2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
